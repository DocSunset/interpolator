# Introduction

In sound design, digital musical instrument design, and intermedia art in
general, creators often deal with complex generative systems with numerous
control parameters: sound and video synthesizers and processors, simulations,
and artificially intelligent agents are a few examples. These systems are often
capable of producing a combinatorially immense variety of interesting behaviors
(sounds, images, etc.) based on the state of their parameters. Much of the
creative work of using and interacting with these systems comes down to
exploring these vast spaces of possibilities, perhaps noting points of interest
along the way. Eventually, entire compositions, installations, or musical
instruments can be devised by selecting the paths to navigate within these
spaces of possibilities.

A useful tool in the exploration and navigation of these spaces is preset
interpolation. After manually recording points of interest in parameter space
as presets, preset interpolation algorithms are used to automatically move
between these predetermined a-priori interesting places, filling in the space
between them with intermediate locations that are likely, by proximity, to also
be interesting. This allows the user of a preset interpolation algorithm to
move easily through the space of possibilities demarcated by the points of
interest they record as presets, facilitating the discovery of other
interesting points in space and of interesting paths through space.

What is especially useful about preset interpolation is that it allows the user
to reframe the navigation of the control parameter space in terms of another
separate space of control sources. For instance, the presets in parameter space
can be associated with locations on a two dimensional map, often significantly
reducing the dimensionality of navigation with an associated reduction in the
difficulty of navigation. Alternatively, the control sources from a complex
gestural interface can be used instead of a two dimensional map, allowing the
destination space to be navigated by moving through the space of gestures
afforded by the interface. These kinds of mappings are often essential in the
design of digital musical instruments, and can be equally rewarding in other
intermedia artistic practices.

# Theory

The basic operating principle of many preset interpolation algorithms,
including the one presented here, is for the user to specify pairs of
source-to-destination associations in the form of presets in these two spaces.
As a concrete example, the user might be exploring the space of sounds produced
by a synthesizer with possibly a very large number of parameters. They might
explore for a while by manually configuring the synthesizer, and note several
particularly interesting preset sound configurations. Then, to facilitate live
performance with the synthesizer, the user may wish to control it with a
graphics tablet. They can associate several locations on the tablet with
different presets found earlier, and then use the preset interpolation
algorithm to navigate between these presets. The tablet locations can also be
thought of as presets, but located in the source space (the tablet's control
dimensions) rather than the destination space (the sound synthesizer
parameters).

To remain unambiguous, for the rest of this exposition preset points in source
space will be refered to as source vectors while preset points in destination
space will be referred to as destination vectors. The word vector reflects the
assumption inherent in most preset interpolation algorithms that the source and
destination spaces are both vector spaces, meaning that presets can be
meaningfully scaled and added together, and that there is a meaningful notion
of distance between presets.  A pair made of a source vector $s$ and a
destination vector $p$ to which the sources in the vicinity of $s$ should be
associated will be called a demonstration, $d = \{s, p\}$. This reflects an
interaction metaphor in which the user is thought to provide demonstrations of
action-to-output relationships, i.e. "when I do $s$, the interpolator should
output $p$."  The symbol $p$ is chosen for destination vectors based on the
common situtation in which the destination space consists of the control
parameters of some media generator such as a sound synthesizer, and to avoid
collision with $d$ for a demonstration of a source-to-destination pair.

The basic principle of many interpolation algorithms is to interpolate between
$N$ destination vectors $p_n$ producing an output vector $y$ in destination
space via a weighted sum with weights given by $\boldsymbol{w}$:

$$
y(\boldsymbol{w}) = \sum_{n = 0}^{N - 1} w_n * p_n
$$

The role of the preset interpolator is then reduced to simply producing and
applying a list of weights, usually as a function of a query or cursor vector
$q$ in the source space, and list $D$ of $N$ demonstrations.

$$
\boldsymbol{w}(q, D) = {w_0, w_1, w_2, ..., w_{n}} 
$$
$$
D = \{s_0, p_0\}, \{s_1, p_1\}, \{s_2, p_2\}, ..., \{s_n, p_n\}
$$

# Intersecting N-Spheres Interpolation

Martin Marier introduced the *intersecting n-spheres interpolation* algorithm
as part of his work with The Sponge, a deformable digital musical instrument
which Marier has been developing for over a decade. This algorithm produces an
interpolated output that is smooth (i.e. continuously differentiable),
continuous, maps from any number of source dimensions to any number of
destination dimensions, exactly passes through the demonstrated destination points,
and locally depends only on nearby demonstrations. The algorithm also
imposes no constraints on the placement of source and destination presets, unlike
other algorithms which might require points to be evenly distributed or
quantized to a grid. Furthermore, the algorithm allows for the position of
presets to be dynamically varied in real-time, allowing the possibility for
higher-level mappings such as navigating destination presets for the preset
interpolation system itself using a higher-level preset interpolator. 

Intersecting n-spheres interpolation produces weights for a weighted sum
according to the following procedure. In summary, for each demonstration two
circles are drawn: one centered on the source vector of the demonstration, and
one centered on the query vector (again in source space). The radius of either
circle is given by the distance from the circle's center point (either the query
vector or the source vector in a demonstration) to its nearest neighbour in
source space (which may again be either the query point or a source vector in
a demonstration). The weight for each demonstration is given by the ratio of
the area of the circle centered on the demonstration's source vector, and the
area of the intersection of that circle with the circle centered on the query
point. The procedure if full proceeds in this way:

1. For every point in source space including the cursor point, determine the
distance from that point to its nearest neighbour in source space. Consider the
distances as the radii of circles centered on their respective points, $r_q$ for
the cursor point $q$, $r_n$ for the $N$ demonstrated source points $s_n$.

2. Determine the distance $d_n$ from each demonstrated source point $s_n$ to
the cursor point $q$.

3. The weight $w_n$ associated with the destination vector $p_n$ of the $n$th
demonstration is given by $A_x(r_q, r_n, d_n) / A(r_n)$ where $A$ is the area
of the circle centered on $s_n$ with radius $r_n$, and

    - where $A_x$ is the area
        - of the intersection 
        - of the circle centered on $s_n$ with radius $r_n$
        - and the circle centered on $q$ with radius $r_q$,
        - whose center points are seperated by the distance $d_n$,
        - with the circles defined to lay on any plane passing through both points.

4. Normalize the weights so that their sum is equal to one by dividing each
weight $w_n$ by the mean of all the weights $\mu = \frac{1}{N}\sum_{n = 0}^{N -
1} w_n$

$A_x$ is given by the following function, which depends only on the radii of
the two circles and the distance between them:

$$
\begin{aligned}
A_x(R, r, d) &= r^2 cos^(-1) ( \frac{d^2 + r^2 - R^2}{2dr} ) \\
             &+ R^2 cos^(-1) ( \frac{d^2 + R^2 - r^2}{2dR} ) \\
             &- \frac{\sqrt{(-d + r + R)(d + r - R)(d - r + R)(d + r + R)}}{2}
\end{aligned}
$$

And the $A$ is given by the usual equation for the area of a circle:
$$
A(r) = \pi r^2
$$

The algorithm, despite its name, actually doesn't involve any n-spheres.
Intead, 2D circles are used, simplifying the algorithm while producing results
that "are predictable and feel natural to the user" according to Marier.

# Implementation

The weighted sum in Marier's algorithm implies that the destination space is
some kind of vector space, while the requirement for a notion of distance
implies that the source space is a normed vector space, most often an Euclidean
vector space. These assumptions are represented in the implementation by the
assumption that the templated `PVector` for the destination space will have an
operator for multiplication by a scalar, and addition of two vectors, and that
the templated `SVector` for the source space will have the same two operators
as well as a method `norm` that returns the length of a vector.

The functions to compute the weight for a single destination vector are
generally straightforward to implement based on the equations above.

One necessary quirk: when the interpolator is used with `float` scalars, the
argument to the `acos` and `sqrt` calls sometimes fall just outside the domain
of the functions. Boundary conditions are checked if `Scalar` is `float`: in
testing, the `acos` args only ever fell at or slightly above `1.0f`, so this
is the only condition which is addressed by the boundary check for these args.

```c++ 
// @='weight functions'
template<typename Scalar>
Scalar circle_circle_intersection_area(
        const Scalar& R, 
        const Scalar& r, 
        const Scalar& d)
{
    Scalar d2 = d * d;
    Scalar r2 = r * r;
    Scalar R2 = R * R;
    Scalar two_d = (Scalar)2 * d;
    Scalar arg1 = (d2 + r2 - R2)/(two_d * r);
    Scalar arg2 = (d2 + R2 - r2)/(two_d * R);
    Scalar arg3 = (-d+r+ R) * (d+r-R) * (d-r+R) * (d+r+R);
    Scalar a, b, c;
    if constexpr (std::is_same_v<Scalar, float>)
    {
        if (arg1 > 1.0f) a = 0;
        else a = r2 * std::acos(arg1);
        if (arg2 > 1.0f) b = 0;
        else b = R2 * std::acos(arg2);
        if (arg3 < 0.0f) c = 0;
        else c = std::sqrt(arg3) / 2.0f;
    }
    else
    {
        a = r2 * std::acos(arg1);
        b = R2 * std::acos(arg2);
        c = std::sqrt(arg3) / (Scalar)2.0;
    }
    return a + b - c;
}

template<typename Scalar>
Scalar circle_area(const Scalar& r)
{
    constexpr Scalar pi = 3.14159265358979323846264338327950288419716939937510582097494459230781640628620899863;
    return pi * r * r;
}

template<typename Scalar>
Scalar marier_spheres_weight(const Scalar& R, const Scalar& r, const Scalar& d)
{
    return circle_circle_intersection_area(R, r, d) / circle_area(r);
}
// @/
```

Step 1 above is an instance of the "all nearest neighbours" problem. We are
given a set of points (the demonstrated points in the source space plus the
cursor point) and for each point $p$ we need to determine the nearest other
point in the space $p_{\text{nearest}}$, which will be used to determine the
radius of the circle associated with $p$.

Efficient algorithms exist which solve the all nearest neighbours problem in
$O(n\log n)$ time, or even in $O(n)$ time if certain constraints are met, which
is most likely the case for this application. Unfortunately, comprehending (let
alone implementing) the linear time algorithms for this problem is non-trivial,
so we opt to use a simpler algorithm until such time as it becomes clear that
optimization is necessary.

Updating any of the points in source space including the cursor point always
requires the nearest neighbour problem to be solved anew, because the nearest
neighbour of the updated point and any point that it was previously the nearest
neighbour of it all have to be updated. Because the position of the cursor
point is assumed to change whenever the interpolator is queried, this means
that the nearest neighbour problem must be solved for every query. The trivial
implementation used here (as well as in Marier's original Supercollider
implementation of the algorithm) solves this problem with $O(n^2)$ time
complexity. In Marier's practice this hasn't been reported as an issue,
presumably because the number of data points has always been reasonably low.

Because the all nearest neighbours problem has to be solved for every query,
there is no need for a special data structure to hold the demonstrations. The
query function could be written as a generic pure function over the query point
and the list of demonstrations. However, for interactive applications (such as
the OpenGL demo program below) it is useful for the caller to query the radii
and weights associated with each demonstration, so room for these is included
in the data structure for holding a demonstration.

```c++ 
// @='intersecting n-spheres'
template<typename Scalar, typename ID, typename SVector, typename PVector>
class MarierSpheresInterpolator
{
public:
    struct Demo { ID id; SVector s; PVector p; Scalar r, d, w;};
    Scalar q_radius;

    template<typename DemoList>
    PVector query(const SVector& q, DemoList& demos, PVector& weighted_sum)
    {
        Scalar sum_of_weights = 0;
        if (demos.size() < 1) return weighted_sum;

        @{find q_radius}

        for (auto& demo : demos)
        {
            @{calculate distance}
        
            @{find radius}
        
            if ((q_radius + demo.r) < demo.d) 
            {
                demo.w = 0;
                continue; // the circles are non-intersecting
            }
            demo.w = marier_spheres_weight(q_radius, demo.r, demo.d);
            sum_of_weights = sum_of_weights + demo.w;
            weighted_sum = weighted_sum + demo.w * demo.p;
        }
        weighted_sum = (1 / sum_of_weights) * weighted_sum;
        for (auto& demo : demos) { demo.w = demo.w / sum_of_weights; }
        return weighted_sum;
    }
};
// @/
```

One quirk of the above implementation is that the output (`weighted_sum`) is
passed by variable. This is necessary to avoid having to initialize `weighted_sum`
to zero. By leaving this responsibility to the caller, the implementation
of the interpolator is more generic, only imposing the need for operators
for addition and multiplication by a scalar. In other words, the interpolator
doesn't know how to initialize a `PVector`, which could be a raw float array,
a complicated linear algebra library vector, or anything else, as long as it
has addition and multiplication by a scalar. Since `PVector` is so generic,
the implementation of the interpolator can't make assumptions about how to
construct or initialize it.

The radius associated with the query point (and indeed every point) is searched
for by brute force. Although far from optimal, this implementation seems good
enough for now.

Although every demonstration will be visited in the main loop of the query
function, the radius of the query point has to be known in advance in order
to calculate the weight associated with each demonstration.

```c++ 
// @='find q_radius'
q_radius = std::numeric_limits<Scalar>::max();
for (const auto& demo : demos)
{
    Scalar d = (demo.s - q).norm();
    if (d < q_radius) q_radius = d;
}
// @/
```

As the query point approaches the position of a demonstrated point, the size of
both $A_x$ and $A$ get smaller and smaller, which would likely lead to
numerical instability when calculating the weight $A_x/A$. For this reason, an
arbitrary amount of sloppiness is introduced into the determination of whether
the query point exactly coincides with a demonstrated point, so that the ratio
$A_x/A$ will not be calculated if the query is too close to a demonstration.
Instead, if the query is close enough to the demonstration then the exact value
of the demonstration is returned and further calculation of the weighted sum is
short-circuited.  This condition is checked while calculating the distance from
the current source vector to the query point, which takes place just before
searching for the radius of the circle centered on the source vector.

```c++ 
// @='calculate distance'
demo.d = (demo.s - q).norm();
constexpr Scalar an_arbitrary_slop_factor = 
    std::numeric_limits<Scalar>::epsilon() * 5;
if (demo.d <= an_arbitrary_slop_factor) return demo.p;
// @/
```

Finding the radius of the circle centered on the demonstration `demo` is done
by brute force search, as mentioned above. The distance from `demo` to ever
other demonstration is checked, and the least distance is recorded. Finally,
the distance from the demonstration to the query point is checked, and this is
used if it is less than the distance from the demonstration to the nearest
other demonstration.

```c++ 
// @='find radius'
demo.r = std::numeric_limits<Scalar>::max();
for (const auto& demo2 : demos)
{
    if (demo.id == demo2.id) continue; // demo cannot be its own nearest neighbour
    Scalar r = (demo.s - demo2.s).norm();
    if (r < demo.r) demo.r = r;
}
if (demo.d < demo.r) demo.r = demo.d; // check if query point is closer
// @/
```

Putting it all together, we get a reasonably generic header-only library
implementing Marier's algorithm.

```c++ 
// @#'interpolator/marier_spheres.h'
#ifndef MARIER_SPHERES_INTERPOLATOR_H
#define MARIER_SPHERES_INTERPOLATOR_H
#include<limits>
#include<cmath>
#include<iostream>

@{weight functions}

@{intersecting n-spheres}
#endif
// @/
```

# Usage

The remainder of this document elaborates some example programs demonstrating
the usage of the library. The drawing example renders an image based on
interpolating randomly generated colors associated with randomly generated 2D
positions. The interactive example works similarly, only instead of
systematically querying the image the user moves a cursor around it to query
the interpolated colors, and the graphics are updated in real time to reflect
the underlying state of the interpolator.

## Drawing example

This simple command line drawing application will randomly generate a handful
of source-destination demonstrations, and draw an image by systematically
querying the source space. As well as producing an image that might offer some
intuition about the topology of the interpolated output, this will also serve
as a reasonable benchmark for the efficiency of the implementation if the
number of pixels in the image is large enough.  The initial implementation of
the interpolator, when compiled with optimizations enabled, could process about
15000 queries per second with 5 demonstrations, about 5000 per second with 15
demonstrations, 2200 with 25 demonstrations, and 1200 with 35 demonstrations.
As per the quadratic time complexity of this implementation, the number of
queries processed per second decreases by a multiplicative factor as the number
of demonstrations increases linearly.

The colour interpolations are performed in [J_zA_zB_z colour
space](https://doi.org/10.1364/OE.25.015131), a colour representation that is
designed to provide the best balance of perceptual uniformity and iso-hue
linearity.  This is meant to ensure that the image produced reflects the
topology of the interpolation rather than the non-linearity of sRGB colour
space. The details of the conversion from RGB (assumed sRGB) through CIE XYZ to
J_zA_zB_z colour space and back are given below.

Here's the overview of the example source code:

```c++ 
// @='basic globals'
using Scalar = float;
using ID = unsigned int;
using Vec2 = Eigen::Vector2f;
using RGBVec = Eigen::Vector3f;
using CIEXYZVec = Eigen::Vector3f;
using JzAzBzVec = Eigen::Vector3f;
using Interpolator = MarierSpheresInterpolator<Scalar, ID, Vec2, JzAzBzVec>;
using Demo = typename Interpolator::Demo;

Interpolator interpolator;
std::vector<Demo> demos;
// @/
```

```c++ 
// @#'examples/color_image.cpp'
#include <cmath>
#include <random>
#include <chrono>
#include <iostream>
#include <vector>
#include "include/fire-hpp/fire.hpp"
#include "include/bitmap/bitmap_image.hpp"
#include "../interpolator/marier_spheres.h"
#include <Eigen/Core>
#include <Eigen/LU>

@{basic globals}

@{colour conversions}

int fired_main(
        unsigned int x = fire::arg("x", "The horizontal dimension in pixels", 500), 
        unsigned int y = fire::arg("y", "The vertical dimension in pixels", 500), 
        unsigned int n = fire::arg("n", "The number of demonstrations", 5))
{
    bitmap_image img(x, y); 
    img.clear();

    @{generate random demonstrations}

    @{draw the image}

    @{draw circles over demonstrated points}

    img.save_image("interpolated_colors.bmp");

    return 0;
}

FIRE(fired_main)
// @/
```

We assume that the source dimensions range from 0 to 1 and that the colour
channels in an RGB colour vector do the same. Randomly generating vectors is
then trivial. The RGB colour vector is then converted to J_zA_zB_z colour space.
It is more convenient to generate the colour vectors in RGB space since doing
so guarantees that the demonstrated colors are possible to display, which may
not be the case when randomly generating colors in J_zA_zB_z space.

```c++ 
// @='generate random demonstrations'
unsigned int seed = std::chrono::system_clock::now().time_since_epoch().count();
std::default_random_engine generator (seed);
std::uniform_real_distribution<Scalar> random(0, 1);
while(n-- > 0)
{
    auto v = Vec2{random(generator), random(generator)};
    auto c = RGB_to_JzAzBz(RGBVec{random(generator), random(generator), random(generator)});
    Demo d{n, v, c};
    demos.push_back(d);
}
// @/
```

Drawing the image is also quite simple; simply iterate over the dimensions of
the image and query the interpolator at each coordinate, convert the resulting
colour to RGB, and then write the colour to the pixel at that coordinate. We
record how long this takes so that the program also serves as a simple
benchmark.

```c++ 
// @='draw the image'
auto start = std::chrono::high_resolution_clock::now();

for (unsigned int xpix = 0; xpix < x; ++xpix)
{
    for (unsigned int ypix = 0; ypix < y; ++ypix)
    {
        auto q = Vec2{xpix/(Scalar)x, ypix/(Scalar)y};
        JzAzBzVec interpolated_jab{0, 0, 0};
        RGBVec out = JzAzBz_to_RGB(interpolator.query(q, demos, interpolated_jab));
        img.set_pixel(xpix, ypix,
                (unsigned char)std::round(out.x() * 255),
                (unsigned char)std::round(out.y() * 255),
                (unsigned char)std::round(out.z() * 255)); 
    }
}

auto stop = std::chrono::high_resolution_clock::now();
auto usec = std::chrono::duration_cast<std::chrono::microseconds>(stop - start).count();
std::cout << "Generated " << x * y << " interpolations in " << usec << " microseconds\n" 
        << "About " << 1000000 * x * y / usec << " interpolations per second" 
        << std::endl;
// @/
```

After drawing the overall image, we also take a moment to draw a circle around
each demonstration point; this helps to better understand how the image relates
to the topology of the interpolator.

```c++ 
// @='draw circles over demonstrated points'
image_drawer draw(img);
draw.pen_width(1);
for (const auto& demo : demos)
{
    const Vec2& v = demo.s;
    const RGBVec& c = demo.p;
    draw.pen_color(0,0,0);
    draw.pen_width(1);
    draw.circle(v.x() * x, v.y() * y, 7);
    draw.pen_color(255,255,255);
    draw.circle(v.x() * x, v.y() * y, 5);
    draw.pen_color(c.x() * 255, c.y() * 255, c.z() * 255);
    draw.pen_width(3);
    draw.circle(v.x() * x, v.y() * y, 2);
}
// @/
```

## OpenGL Interactive Example

This example offers some insight into the inner workings of the interpolator.
A handful of demonstrations associating random 2D positions with random colors
are generated. The position and colour of each point is visualized by drawing a
dot of the appropriate colour at that position. In addition, a circle is drawn
around each dot with the radius associated to that demonstration by the
interpolator; notice how each demonstrated point's radial circle always
intersects at least one other dot, which is the nearest neighbour of that
demonstrated point. Finally, a grey region is drawn beneath each dot whose size
and brightness reflect the contribution of that dot to the weighted sum. 

The position of the query point is based on the position of the cursor within
the screen. Its colour is based on the result of the interpolation. A radial
circle is also drawn for this point.

The bulk of this happens in the display callback. For some reason, it appears
to be necessary to draw in depth order (back to front) so that the dots and
radial lines dont become obscured by the weight disk in the back. If anyone
can explain why this is, please contact me. The z-coordinate doesn't appear to
have any influence, even with depth testing enabled.

```c++ 
// @='display callback'
void drawCircle(const Vec2& position, const Scalar& radius, const Scalar& depth = 0)
{
    constexpr Scalar pi = 3.14159265358979323846264338327950288419716939937510582097494459230781640628620899863;
    for (float w = 0; w <= 2 * pi; w += 0.1)
    {
        glVertex3f(
                position.x() + std::cos(w) * radius, 
                position.y() + std::sin(w) * radius,
                depth);
    }
}

void drawCircleFilled(const Vec2& position, const Scalar& radius, const Scalar& depth = 0)
{
    glBegin(GL_POLYGON);
    drawCircle(position, radius, depth);
    glEnd();
}

void drawCircleWire(const Vec2& position, const Scalar& radius, const Scalar& depth = 0)
{
    glBegin(GL_LINE_LOOP);
    drawCircle(position, radius, depth);
    glEnd();
}

void display()
{
    constexpr float dot_radius = 0.01;
    JzAzBzVec interpolated_jab{0, 0, 0};
    RGBVec q_color = JzAzBz_to_RGB(interpolator.query(q, demos, interpolated_jab));

    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

    for (const auto& d : demos)
    {
        const auto& v = d.s;
        // draw disk for weight
        glColor4f(d.w, d.w, d.w, d.w);
        drawCircleFilled(v, d.w/3, -1);
    }

    for (const auto& d : demos)
    {
        const auto& v = d.s;
        const auto c = JzAzBz_to_RGB(d.p);
        // draw radial circle
        glColor3f(c.x(), c.y(), c.z());
        drawCircleWire(v, d.r, 1);
        drawCircleWire(v, d.r - 0.001, 1);
    }

    for (const auto& d : demos)
    {
        const auto& v = d.s;
        const auto c = JzAzBz_to_RGB(d.p);
        // draw colored dots
        glColor3f(c.x(), c.y(), c.z());
        drawCircleFilled(v, dot_radius, 1);
    }

    glColor3f(q_color.x(), q_color.y(), q_color.z());
    drawCircleWire(q, interpolator.q_radius);
    drawCircleWire(q, interpolator.q_radius - 0.001);
    drawCircleFilled(q, dot_radius, 1);

    glutSwapBuffers();
}
// @/
```

All of the points in the scene in world coordinates are in the square region
([0 - 1], [0 - 1]). The reshape callback appropriately sets the viewport and
projection matrices to ensure this region is visible and undistorted. In case
the window is wider than it is tall, padding is added on the sides so that the
scene is centered. Otherwise, when the window is taller than it is wide, the
padding is added above and below the scene.

```c++ 
// @='reshape callback'
void reshape(int w, int h)
{
    glViewport(0,0,w,h);
    glMatrixMode(GL_PROJECTION);
    glLoadIdentity();
    if (h < w)
    {   // the window is a wide rectangle
        @{h < w: calculate pixels_per_unit and offset}
        glOrtho(-offset, 1 + offset, 0,       1, -1, 1);
    }
    else
    {   // the window is a tall rectangle (or square)
        @{w <= h: calculate pixels_per_unit and offset}
        glOrtho(0,       1,          -offset, 1 + offset, -1, 1);
    }
}
// @/
```

```c++ 
// @='h < w: calculate pixels_per_unit and offset'
Scalar padding = (w - h)/2; // there is `padding` space on either size of the scene square
Scalar pixels_per_unit = h; // this many pixels per unit in world coordinates
Scalar units_per_pixel = 1/pixels_per_unit;
Scalar offset = padding * units_per_pixel;
// @/
```

```c++ 
// @='w <= h: calculate pixels_per_unit and offset'
Scalar padding = (h - w)/2; // there is `padding` space above and below the scene square
Scalar pixels_per_unit = w; // this many pixels per unit in world coordinates
Scalar units_per_pixel = 1/pixels_per_unit;
Scalar offset = padding * units_per_pixel;
// @/
```

The position of the query vector `q` is updated in the mouse move callback.
This requires a similar calculation as the reshape callback, only going the
other direction.

This callback also drives updates to the display, since moving the cursor
will change the state of the interpolator.

```c++ 
// @='motion callback'
void mouse_move(int x, int y)
{
    y = glutGet(GLUT_WINDOW_HEIGHT) - y; // flip y so it goes from the bottom left
    int w = glutGet(GLUT_WINDOW_WIDTH);
    int h = glutGet(GLUT_WINDOW_HEIGHT);
    if (h < w)
    {   // the window is a wide rectangle
        @{h < w: calculate pixels_per_unit and offset}
        q.x() = (Scalar)x / pixels_per_unit - offset;
        q.y() = (Scalar)y / pixels_per_unit;
    }
    else
    {   // the window is a tall rectangle (or square)
        @{w <= h: calculate pixels_per_unit and offset}
        q.x() = (Scalar)x / pixels_per_unit;
        q.y() = (Scalar)y / pixels_per_unit - offset;
    }
    glutPostRedisplay();
}
// @/
```

The rest of the program is basically boilerplate for setting up openGL. The
global `using` declarations are the same as in the drawing example.

```c++ 
// @='setup display and callbacks'
// fake argv and argc since we can't access the real ones behind fire-hpp
char * fake_argv[1];
std::string prog_name = "interactive_colors";
fake_argv[0] = &*prog_name.begin();
int fake_argc = 1;

glutInit(&fake_argc, fake_argv);
glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGBA);
glutInitWindowPosition(0,0);
glutInitWindowSize(500,500);
glutCreateWindow("Interactive Interpolator Demo");
glutMotionFunc(mouse_move);
glutPassiveMotionFunc(mouse_move);
glutDisplayFunc(display);
glutReshapeFunc(reshape);
glEnable(GL_DEPTH_TEST);
glClearColor(0,0,0,0);
glClear(GL_COLOR_BUFFER_BIT);
glutSwapBuffers();
// @/
```

```c++ 
// @#'examples/interactive_colors.cpp'
#include <string>
#include <cmath>
#include <chrono>
#include <random>
#include <iostream>
#include <GL/gl.h>
#include <GL/glut.h>
#include <Eigen/Core>
#include <Eigen/LU>
#include "include/fire-hpp/fire.hpp"
#include "../interpolator/marier_spheres.h"

@{basic globals}
@{colour conversions}
Vec2 q = {0,0};

@{display callback}

@{reshape callback}

@{motion callback}

int fired_main(unsigned int n = fire::arg("n", "The number of demonstrations", 5))
{
    @{generate random demonstrations}

    @{setup display and callbacks}

    glutMainLoop();

    return 0;
}

FIRE(fired_main)
// @/
```

## Converting RGB to perceptually uniform colour space

As mentioned above, the interpolator in the drawing example uses a perceptually
uniform colour space called J_zA_zB_z to ensure that the topology of the
interpolator is well represented by the image without distortion by the
non-linear relationship of the colour representation to typical human colour
vision. Since the colours are rendered in RGB, it is necessary to convert RGB
to and from J_zA_zB_z It is assumed that the RGB colour values will be
interpreted and displayed by the system as
[sRGB](https://en.wikipedia.org/wiki/SRGB), a reasonable default assumption due
to the ubiquitous use of this standard colour space on the web, OpenGL, and
other standards and consumer optical equipment.  Both sRGB and J_zA_zB_z colour
spaces are defined relative to [CIE
XYZ](https://en.wikipedia.org/wiki/CIE_1931_color_space) colour space, a
standard colour space defined by the International Commission on Illumination
in 1931 that defines a quantitative representation of the physiological
response of the eye as it relates to the perception of a certain colour. Given
this shared root, converting to or from sRGB to J_zA_zB_z requires first
converting to or from CIE XYZ.  We assume that the sRGB values are normalized
between 0.0 and 1.0, that the CIE XYZ Y value ranges between 0.0 and 1.0.

The conversion between sRGB and CIE XYZ is given in [the wikipedia page on
sRGB](https://en.wikipedia.org/wiki/SRGB). Since the example programs make use
of Eigen for their colour data, the conversion can be succinctly implemented
with matrix multiplication and other Eigen features.

```c++
// @='RGB - XYZ colour conversions'
RGBVec XYZ_to_RGB(const CIEXYZVec& xyz)
{
    RGBVec rgb;
    Eigen::Matrix3f a;
    a <<  3.24096994, -1.53738318, -0.49861076,
         -0.96924364,  1.8759675,   0.04155506,
          0.05563008, -0.20397696,  1.05697151;

    rgb = a * xyz; // apply linear transformation

    for (unsigned int i = 0; i < 3; i++) // apply gamme correction
    {
        auto u = rgb[i];
        u = u > 0.0031308 ? (1.055 * pow(u, 1 / 2.4) - 0.055) : 12.92 * u;
        u = u < 0.0 ? 0.0 : u;
        u = u > 1.0 ? 1.0 : u;
        rgb[i] = u;
    }

    return rgb;
}

CIEXYZVec RGB_to_XYZ(const RGBVec& rgb)
{
    CIEXYZVec xyz = rgb;
    Eigen::Matrix3f a;
    a <<  0.41239080,  0.35758434,  0.18048079,
          0.21263901,  0.71516868,  0.07219232,
          0.01933082,  0.11919478,  0.95053215;

    for (unsigned int i = 0; i < 3; i++) // reverse gamme correction
    {
        auto u = xyz[i];
        u = u > 0.04045 ? pow((u + 0.055) / 1.055, 2.4) : u / 12.92;
        xyz[i] = u;
    }

    return a * xyz; // reverse linear transformation
}
// @/
```

The conversion between J_zA_zB_z and CIE XYZ is given in [the 2017 paper by Safdar
et al. introducing J_zA_zB_z published by the Optical Society of America in Volume
25 Issue 13 pages 15131-15151 of the journal Optics
Express](https://doi.org/10.1364/OE.25.015131).

```c++
// @='JzAzBz consts'
static const Eigen::Matrix3f M1 = (Eigen::Matrix3f() <<
    0.41478972,  0.579999,  0.0146480,
    -0.2015100,  1.120649,  0.0531008,
    -0.0166008,  0.264800,  0.6684799).finished();
static const Eigen::Matrix3f M2 = (Eigen::Matrix3f() <<  
    0.5,         0.5,       0.0,
    3.524000,   -4.066708,  0.542708,
    0.199076,    1.096799, -1.295875).finished();
constexpr float two5 = 1 << 5;
constexpr float two7 = 1 << 7;
constexpr float two12 = 1 << 12;
constexpr float two14 = 1 << 14;
constexpr float b = 1.15;
constexpr float g = 0.66;
constexpr float c1 = 3424.0 / two12;
constexpr float c2 = 2413.0 / two7;
constexpr float c3 = 2392.0 / two7;
constexpr float n = 2610.0 / two14;
constexpr float p = 1.7 * 2523.0 / two5;
constexpr float d = -0.56;
constexpr float d_0 = 1.6295499532821566e-11;
// @/

// @='JzAzBz - XYZ colour conversions'
JzAzBzVec XYZ_to_JzAzBz(const CIEXYZVec& xyz)
{
    @{JzAzBz consts}
    auto x = xyz.x();
    auto y = xyz.y();
    auto z = xyz.z();

    // pre-adjust to improve iso-hue linearity (Safdar et al. eqn. 8
    auto x_ = b * x - (b - 1.0) * z;
    auto y_ = g * y - (g - 1.0) * x;
    CIEXYZVec xyz_(x_, y_, z);

    // transform xyz to cone primaries (Safdar et al. eqn. 9)
    Eigen::Vector3f lms = M1 * xyz_;

    // perceptual quantizer (Safdar et al. eqn. 10
    for (unsigned int i = 0; i < 3; ++i)
    {
        auto u = pow(lms[i] / 10000.0, n);
        lms[i] = pow( (c1 + c2 * u) / (1.0 + c3 * u), p );
    }

    // transform to correlates of opponent colour space (Safdar et al. eqn. 11)
    Eigen::Vector3f jab = M2 * lms;

    // improve wide-range lightness prediction (Safdar et al. eqn. 12)
    auto i = jab[0];
    jab[0] = ((1.0 + d) * i) / (1.0 + d * i) - d_0;

    return jab;
}

CIEXYZVec JzAzBz_to_XYZ(const JzAzBzVec& jab)
{
    @{JzAzBz consts}
    static const Eigen::Matrix3f M1inv = M1.inverse();
    static const Eigen::Matrix3f M2inv = M2.inverse();

    // eqn. 17
    auto iab = jab;
    auto j = jab[0] + d_0;
    iab[0] = j / (1.0 + d - d * j);

    // eqn. 18
    Eigen::Vector3f lms = M2inv * iab;

    // eqn. 19
    for (unsigned int i = 0; i < 3; ++i)
    {
        auto u = pow(lms[i], 1.0/p);
        lms[i] = 10000.0 * pow( (c1 - u) / (c3 * u - c2), 1.0/n );
    }

    // eqn. 20
    auto xyz_ = M1inv * lms;

    // eqn. 21 - 23
    auto x_ = xyz_[0];
    auto y_ = xyz_[1];
    auto z_ = xyz_[2];
    auto x = (x_ + (b - 1.0) * z_) / b;
    auto y = (y_ + (g - 1.0) * x) / g;
    auto z = z_;

    CIEXYZVec xyz{x, y, z};
    return xyz;
}
// @/
```

The conversion between sRGB and J_zA_zB_z is then easily implemented in terms
of the above conversions to and from CIE XYZ colour space:

```c++
// @='colour conversions'
@{RGB - XYZ colour conversions}

@{JzAzBz - XYZ colour conversions}

JzAzBzVec RGB_to_JzAzBz(const RGBVec& rgb)
{
    return XYZ_to_JzAzBz(RGB_to_XYZ(rgb));
}

RGBVec JzAzBz_to_RGB(const JzAzBzVec& jab)
{
    return XYZ_to_RGB(JzAzBz_to_XYZ(jab));
}
// @/
```

## Compiling Examples

Both examples are relatively simple with just a few dependencies. Both rely
on Eigen, and the interactive example additionally requires OpenGL. Make sure
that these libraries are installed on your system. The other dependencies 
(fire-hpp and bitmap) are both included as subtrees in this repository, so you
should not have to do anything to install them.

A simple Makefile is included in this repository with rules for building the
examples, as well as for generating the machine source code and pretty-printed
source code from this literate source code document using
[`lilit`](https://github.com/DocSunset/lilit). The Makefile is tested and
working on the author's Arch Linux system. As usual, I am open to
recommendations and pull requests to improve the compatibility of the Makefile.
