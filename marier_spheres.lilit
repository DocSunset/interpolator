# Background

In sound design, digital musical instrument design, and intermedia art in
general, creators often deal with complex generative systems with numerous
control parameters: sound and video synthesizers and processors, simulations,
and artificially intelligent agents to name just a few. These systems are often
capable of producing a combinatorially immense variety of interesting behaviors
(sounds, images, etc.) based on the state of their parameters. Much of the
creative work of using and interacting with these systems often comes down to
simply exploring these vast spaces of possibilities, perhaps noting points of
interest along the way. Eventually, entire compositions, installations, or
musical instruments can be devised by selecting the most meaningful or
appropriate paths to navigate within these spaces of possibilities.

A useful tool in the exploration and navigation of these spaces is preset
interpolation. Recording the points of interest found during manual exploration
of a given space as presets, preset interpolation algorithms are used to
automatically move from one preset to another, or from one preset place to a
point in the space that is intermediate between that preset and several other
interesting places. This allows the user of a preset interpolation algorithm to
move easily through the space of possibilities demarcated by the points of
interest they record as presets, facilitating the discovery of other
interesting points in space and of interesting paths through space.

What is especially useful preset interpolation is that it allows the user to
reframe the navigation of the control parameter space in terms of another
separate space of control sources. For instance, the presets in parameter space
can be associated with locations on a two dimensional map, often significantly
reducing the dimensionality of navigation with an associated reduction in the
difficulty of navigation. Alternatively, the control sources from a complex
gestural interface can be used instead of a two dimensional map, allowing the
destination space to be navigated by moving through the space of gestures
afforded by the interface. These kinds of mappings are often essential in the
design of digital musical instruments, and can be equally rewarding in other
intermedia artistic practices.

The basic operating principle of many preset interpolation algorithms,
including the one presented here, is for the user to specify pairs of
source-to-destination associations in the form of presets in these two spaces. So
for instance, the user might explore a bit by hand and record several parameter
presets that produce interesting behaviors. Then the user might specify several
positions on a 2D surface and associate each 2D location with a parameter
location. Both the 2D locations and the parameter presets are considered as
points in euclidean spaces; in this example the source space has two
dimensions, while the destination space has as many dimensions are there are
parameters. The points can be considered as presets in their respective spaces.

To remain unambiguous, for the rest of this exposition preset points in source
space will be refered to as source vectors while preset points in destination
space will be referred to as destination vectors. The word vector reflects the
assumption inherent in to most preset interpolation algorithms that the source
and destination spaces are both vector spaces, i.e. that multiplying a source
or destination vector by a scalar and adding two vectors from the same space
are both meaningful operations which satisfy certain requirements. A pair made
of a source vector $s$ and a destination vector $p$ to which the sources in the
vicinity of $s$ should be associated will be called a demonstration. This
reflects an interaction metaphor in which the user is thought to provide
demonstrations of action-to-output relationships, i.e. "when I do $s$, the
interpolator should output $p$."

The basic principle of many interpolation algorithms is to interpolate between
destination vectors producing an output parameter vector $y$ via a weighted sum.

y = \sum_{i = 0}^{A - 1} w_i * p_i

Where $|D|$ is the number of demonstrations (i.e. the size of the set $D$ of
demonstrations). The role of the preset interpolator is then reduced to simply
producing a list of weights, usually as a function of a query or cursor vector
$q$ in the source space, and the list of demonstrations.

\bm{w}(q, D) = {w_0, w_1, w_2, ..., w_{|D|}}
D = { {s_0, p_0}, {s_1, p_1}, {s_2, p_2}, ..., {s_|D|, p_|D|} }

# Interaction

A handful of operations can be supported by a preset interpolation algorithm to
allow the user to interact with the system.  

- add/remove a demonstration including both a source and destination point
- change the recorded state of point (move the point's position in state space)
- query the interpolated destination value for a given source value

Most interpolation algorithms will require some kind of internal data structure
for representing demonstrations so that queries can be performed efficiently.
Changing the recorded state of a point is likely to require an update to this
data structure, as is adding or removing demonstrations (whether directly or
via associating or deassociating already specified points). In many cases it
may be more efficient to batch process such updates, especially in case a large
number of points are moved or demonstrations added all at once.  For
interpolators in which this is not the case, default batch editing methods may
be provided.

Based on these requirements, base classes for interpolators and demonstrations
can be outlined.

@='interpolator base class'
template<typename Scalar, typename S, typename P>
struct Demonstration
{
    using SVector = S;
    using PVector = P;
    std::string name;
    SVector s;
    PVector p;
};

template<typename Demo>
struct DemonstrationHash
{
    std::size_t operator()(const Demo& d) const noexcept
    {
        return std::hash<std::string>{}(d.name);
    }
};

template<typename Scalar, typename S, typename P>
class PresetInterpolator
{
public:
    using SVector = S;
    using PVector = P;
    using Demo = Demonstration<Scalar, SVector, PVector>;

    virtual void add_demo(const Demo& d) = 0;
    virtual void update_demo(const Demo& d) = 0;
    virtual void remove_demo(const Demo& d) = 0;
    virtual PVector query(const SVector& s) = 0;

    template<typename DemoList>
    void add_demo(const DemoList& demos) 
    {
        for (const Demo& d : demos) add_demo(d);
    }

    template<typename DemoList>
    void update_demo(const DemoList& demos)
    {
        for (const Demo& d : demos) update_demo(d);
    }

    template<typename DemoList>
    void remove_demo(const DemoList& demos)
    {
        for (const Demo& d : demos) remove_demo(d);
    }
};
@

# Intersecting N-Spheres Interpolation

Martin Marier introduced the *intersecting n-spheres interpolation* algorithm
as part of his work with The Sponge, a deformable digital musical instrument
which Marier has been developing for over a decade. This algorithm produces an
interpolated output that is smooth (i.e. continuously differentiable),
continuous, maps from any number of source dimensions to any number of
destination dimensions, exactly passes through the demonstrated destination points,
and locally depends only on nearby demonstrations. The algorithm also
imposes no constraints on the placement of source and destination presets, unlike
other algorithms which might require points to be evenly distributed or
quantized to a grid. Furthermore, the algorithm allows for the position of
presets to be dynamically varied in real-time, allowing the possibility for
higher-level mappings such as navigating destination presets for the preset
interpolation system itself using a higher-level preset interpolator. 

Intersecting n-spheres interpolation produces weights for a weighted sum
according to the following procedure:

1. For every point in source space including the cursor point, determine the
distance ($R$ for the cursor point, $r_i$ for the demonstrated source points)
from that point to its nearest neighbour in source space. Consider the
distances $R$ and $r_i$ as the radii of circles centered on their respective
points.

2. Determine the distance $d_i$ from each demonstrated source point $s_i$ to
the cursor point.

3. The weight $w_i$ associated with the destination vector $p_i$ of the $i$th
demonstration is given by the $A_x(R, r_i, d_i) / A(r_i)$ where $A_x$ is the
area of the intersection of the circles defined by $R$, $r_i$, and their
respective data points as though the circles lay on a plane passing through
both points, and $A$ is the area of the circle defined by $r_i$ and its point.
$A_x$ is given by the following function, which depends only on the radii of
the two circles and the distance between them:

A_x(R, r, d) &= r^2 cos^(-1) \( \frac{d^2 + r^2 - R^2}{2dr} \)
             &+ R^2 cos^(-1) \( \frac{d^2 + R^2 - r^2}{2dR} \)
             &- \frac{\sqrt{(-d + r + R)(d + r - R)(d - r + R)(d + r + R)}}{2}

4. Normalize the weights so that their sum is equal to one.

The algorithm, despite its name, actually doesn't utilized hyperspheres.
Intead, 2D areas are used, simplifying the algorithm while producing results
that "are predictable and feel natural to the user" according to Marier.

# Implementation

The weighted sum in Marier's algorithm implies that the destination space is
some kind of vector space, while the requirement for a notion of distance
implies that the source space is a normed vector space, most often an Euclidean
vector space. These assumptions are represented in the implementation by the
assumption that the templated PVector for the destination space will have an
operator for multiplication by a scalar, and addition of two vectors, and that
the templated SVector for the source space will have the same two operators as
well as a function `Scalar norm(SVector a, SVector b)` that returns the
distance between two SVectors.

The functions to compute the weight for a single destination vector are
straightforward to implement based on the equations in step 3 above

@='weight functions'
template<typename Scalar>
Scalar circle_circle_intersection_area(
        const Scalar& R, 
        const Scalar& r, 
        const Scalar& d)
{
    Scalar d2 = d * d;
    Scalar r2 = r * r;
    Scalar R2 = R * R;
    Scalar two_d = 2 * d;
    Scalar a = r2 * std::acos((d2 + r2 - R2)/(two_d * r));
    Scalar b = R2 * std::acos((d2 + R2 - r2)/(two_d * R));
    Scalar c = std::sqrt((-d+r+ R) * (d+r-R) * (d-r+R) * (d+r+R))/2.0;
    return a + b - c;
}

template<typename Scalar>
Scalar circle_area(const Scalar& r)
{
    constexpr Scalar pi = 3.14159265358979323846264338327950288419716939937510582097494459230781640628620899863;
    return pi * r * r;
}

template<typename Scalar>
Scalar weight(const Scalar& R, const Scalar& r, const Scalar& d)
{
    return circle_circle_intersection_area(R, r, d) / circle_area(r);
}
@

Step 1 above is an instance of the "all nearest neighbours" problem. We are
given a set of points (the demonstrated points in the source space plus the
cursor point) and for each point $p$ we need to determine the nearest other
point in the space $p_{\text{nearest}}$, which will be used to determine the
radius of the circle associated with $p$.

Efficient algorithms exist which solve the all nearest neighbours problem in
$O(n\log n)$ time, or even in $O(n)$ time if certain constraints are met, which
is most likely the case for this application. Unfortunately, comprehending the
linear time algorithms for this problem is non-trivial, so we opt to use a
simpler algorithm until such time as it becomes clear that more optimization is
necessary.

Updating any of the points in source space including the cursor point always
requires the nearest neighbour problem to be solved anew, because the nearest
neighbour of the updated point and any point that it was previously the nearest
neighbour of will all have to be updated. Because the position of the cursor
point is assumed to change whenever the interpolator is queried, this means
that the nearest neighbour problem must be solved for every query. The trivial
implementation used here (as well as in Marier's original presentation of the
interpolation algorithm) solves this problem with $O(n^2)$ time complexity. In
Marier's practice this hasn't been reported as an issue, presumably because the
number of data points has always been reasonably low.

We will use an unordered set to store demonstrations, allowing easy removal and
update of specific demonstrations. We will also define a new `Demo` subclass
to store the information specific to intersecting n-spheres interpolation.
Adding, removing, and updating data points simply edits the set accordingly;
updating the radius and distance associated with each point is done when
querying the interpolator.

To facilitate brevity in the implementation of the all nearest neighbours
problem, the query point is also included in the set of points as a special
demonstration named according to the value of the `cursor_name` constant. This
demonstration cannot be removed.

@='intersecting n-spheres data structures'

template<typename Scalar, typename S, typename P>
class MarierSpheresInterpolator : public PresetInterpolator<Scalar, S, P>
{
public:
    struct Circle { Scalar r; Scalar d; };
    using Parent = PresetInterpolator<Scalar, S, P>;
    using Demo = typename Parent::Demo;
    using SVector = typename Parent::SVector;
    using PVector = typename Parent::PVector;
    const std::string cursor_name = "/cursor";

    MarierSpheresInterpolator() {add_demo({cursor_name,{},{}});}
    const Circle& get_cursor() 
    {
        auto it = set.find(cursor_name);
        return it->second.second;
    }

    void set_cursor(const SVector& q) 
    {
        Demo cursor = {cursor_name,q,{}};
        update_demo(cursor);
    }

    void add_demo(const Demo& d) override
    {
        set.insert({d.name, std::pair<Demo, Circle>({d, {}})});
    }

    void update_demo(const Demo& d) override
    {
        auto prior_it = set.find(d.name);
        if (prior_it != set.end()) 
        {
            Demo& p = prior_it->second.first;
            p = d;
        }
    }

    void remove_demo(const Demo& d) override
    {
        if (d.name == cursor_name) return; // silently ignore if the caller tries to remove the cursor
        set.erase(d.name);
    }

    PVector query(const SVector& q) override
    {
        if (set.size() < 2) return PVector();
        set_cursor(q);

        @{solve the all nearest neighbours problem}

        @{calculate weights and weighted sum}
    }

private:
    std::unordered_map<std::string, std::pair<Demo, Circle>> set;
};
@

We are not actually concerned with knowing which point is nearest any other,
but only wish to know the distance from each point to its nearest neighbour.
For this reason no special datastructure is used to represent the nearest
neighbour graph; instead the radii are simply recorded in the `Circle` structs
associated with each demonstration as they come up.

While we're iterating over all the demonstrated points, we also take the
opportunity to record the distance from each point to the query point q, and
catch the special case that the query point exactly lies at the position of
a demonstrated point. In such cases, the output of the interpolator is simply
the destination vector associated with that demonstration, and no further work
is necessary.

As the query point approaches the position of a demonstrated point, the size of
both $A_x$ and $A$ get smaller and smaller, which would likely lead to
numerical instability when calculating the weight $A_x/A$. For this reason, an
arbitrary amount of sloppiness is introduced into the determination of whether
the query point exactly coincides with a demonstrated point, so that the ratio
$A_x/A$ will not be calculated if the query is too close to a demonstration.

@='solve the all nearest neighbours problem'
for (auto& pair1 : set)
{
    auto& data = pair1.second;
    const auto& d1 = data.first;
    auto& circle = data.second;
    if (d1.name != cursor_name)
    {
        Scalar distance = norm(d1.s - q);
        constexpr Scalar an_arbitrary_slop_factor = 
                std::numeric_limits<Scalar>::epsilon() * 5;
        if (distance <= an_arbitrary_slop_factor) return d1.p;

        circle.d = distance;
    }

    Scalar radius = std::numeric_limits<Scalar>::max();
    for (const auto& pair2 : set)
    {
        const auto& d2 = pair2.second.first;
        if (d1.name == d2.name) continue;
        Scalar distance = norm(d1.s - d2.s);
        if (distance < radius) radius = distance;
    }
    circle.r = radius;
}
@

All that leaves is producing the output. Rather than calculating the weights,
normalizing them, and then integrating the weighted sum, the weighted sum is
integrated as the weights are calculated, and the sum is normalized afterwards
based on the sum of the weights; the two approaches are mathematically
equivalent according to the following equation, but as implemented the routine
is somewhat more succinct and avoids having to allocate memory at runtime to
store an unknown number of weights.

  &(\frac{1}{z} * w_0 * p_0) + (\frac{1}{z} * w_1 * p_1) + ... + (\frac{1}{z} * w_2 * p_2)
= &((w_0 * p_0) + (w_1 * p_1) + ... + (w_2 * p_2)) * \frac{1}{z}

Where $z$ is the normalization factor equal to the sum of all $w_i$.

@='calculate weights and weighted sum'
Scalar sum_of_weights = 0;
PVector weighted_sum{};
Scalar q_radius = get_cursor().r;
for (const auto& pair : set)
{
    const auto& data = pair.second;
    const auto& demo = data.first;
    if (demo.name == cursor_name) continue;
    const auto& circle = data.second;
    if ((q_radius + circle.r) < circle.d) continue; // the circles are non-intersecting

    Scalar w = weight(q_radius, circle.r, circle.d);
    sum_of_weights += w;
    weighted_sum += w * demo.p;
}
weighted_sum = (1 / sum_of_weights) * weighted_sum;
return weighted_sum;
@

Putting it all together, we get a reasonably generic header-only library
implementing Marier's algorithm.

@#'include/marier_spheres.h'
#include<unordered_map>
#include<limits>
#include<string>
#include<cstddef>
#include<cmath>

@{interpolator base class}

@{weight functions}

@{intersecting n-spheres data structures}
@

# Usage

We will exercise `intersecting_spheres.h` in a simple command line drawing
application; the source space will be 2D coordinates, and the destination space
an RGB color value. The program will randomly generate a handful of
source-destination demonstrations, and draw an image by systematically querying
the space. As well as producing an image that might offer some intuition about
the topology of the interpolated output, this will also serve as a reasonable
benchmark for the efficiency of the implementation if the number of pixels in
the image is large enough.

For command line parsing, we'll use kongaskristjan's `fire-hpp`. The program
takes arguments for the dimensions of the image (`-x` and `-y`) and the number
of demonstrations to randomly generate (`-n`).

For image drawing we'll use ArashPartow's `bitmap` library.

Here's the overview of the example source code:

@#'examples/color_interpolator.cpp'
#include <cmath>
#include <random>
#include <string>
#include <chrono>
#include <iostream>
#include "../include/fire-hpp/fire.hpp"
#include "../include/bitmap/bitmap_image.hpp"
#include "../include/marier_spheres.h"

@{Vec2 datatype}

@{RGB datatype}

int fired_main(
        unsigned int x = fire::arg("x", "The horizontal dimension in pixels", 500), 
        unsigned int y = fire::arg("y", "The vertical dimension in pixels", 500), 
        unsigned int n = fire::arg("n", "The number of demonstrations", 25))
{
    using Scalar = float;
    using Vec2 = Vec2<Scalar>;
    using RGBVec = RGBVec<Scalar>;
    using Demo = Demonstration<Scalar, Vec2, RGBVec>;
    MarierSpheresInterpolator<Scalar, Vec2, RGBVec> interpolator;

    bitmap_image img(x, y); 
    img.clear();

    @{generate random demonstrations and draw image}

    img.save_image("interpolated_colors.bmp");

    return 0;
}

FIRE(fired_main)
@

In use, we assume that the source dimensions range from 0 to 1 and that the 
color channels in the RGBVec do the same. Randomly generating vectors is then
trivial.

Drawing the image is also quite simple; simply iterate over the dimensions of
the image and query the interpolator at each coordinate. 

@='generate random demonstrations and draw image'
unsigned int seed = std::chrono::system_clock::now().time_since_epoch().count();
std::default_random_engine generator (seed);
std::uniform_real_distribution<Scalar> random(0, 1);
auto start = std::chrono::high_resolution_clock::now();
while(n-- > 0)
{
    auto v = Vec2{random(generator), random(generator)};
    auto c = RGBVec{random(generator), random(generator), random(generator)};
    Demo d{std::to_string(n), v, c};
    interpolator.add_demo(d);
}

for (unsigned int xpix = 0; xpix < x; ++xpix)
{
    for (unsigned int ypix = 0; ypix < y; ++ypix)
    {
        auto q = Vec2{xpix/(Scalar)x, ypix/(Scalar)y};
        auto out = interpolator.query(q) * (Scalar)255;
        float test = xpix/(float)x * 255;
        img.set_pixel(xpix, ypix, 
                (unsigned char)std::round(out.red),
                (unsigned char)std::round(out.green),
                (unsigned char)std::round(out.blue)); 
    }
}
auto stop = std::chrono::high_resolution_clock::now();
auto usec = std::chrono::duration_cast<std::chrono::microseconds>(stop - start).count();
std::cout << "Generated " << x * y << " interpolations in " << usec << " microseconds\n" 
        << "About " << 1000000 * x * y / usec << " interpolations per second" 
        << std::endl;
@

The remainder of the example program is spent mostly on boilerplate defining
arithmetic operations for our two vector spaces.  The `bitmap` library provides
an RGB pixel type, but without any operators and only 8-bit depth per channel.
To satisfy the requirements of a vector space needed for the interpolator and
avoid saturating our output image, we define our own pixel type with float
resolution and the required operators.  

@='RGB datatype'
template<typename Scalar> struct RGBVec
{
    Scalar red;
    Scalar green;
    Scalar blue;

    Scalar max() const {return std::max({red, green, blue});}
};

template<typename Scalar>
RGBVec<Scalar> operator+(const RGBVec<Scalar>& a, const RGBVec<Scalar>& b)
{
    return {a.red + b.red, a.green + b.green, a.blue + b.blue};
}

template<typename Scalar>
RGBVec<Scalar> operator-(const RGBVec<Scalar>& a, const RGBVec<Scalar>& b)
{
    return {a.red - b.red, a.green - b.green, a.blue - b.blue};
}

template<typename Scalar>
RGBVec<Scalar>& operator+=(RGBVec<Scalar>& a, const RGBVec<Scalar>& b)
{
    return a = a + b;
}

template<typename Scalar>
RGBVec<Scalar>& operator-=(RGBVec<Scalar>& a, const RGBVec<Scalar>& b)
{
    return a = a - b;
}

template<typename Scalar>
RGBVec<Scalar> operator*(const Scalar& w, const RGBVec<Scalar>& c)
{
    return {c.red * w, c.green * w, c.blue * w};
}

template<typename Scalar>
RGBVec<Scalar> operator*(const RGBVec<Scalar>& c, const Scalar& w)
{
    return w * c;
}
@

For the source space we define a simple 2D vector type.

@='Vec2 datatype'
template<typename Scalar> struct Vec2
{
    Scalar x;
    Scalar y;
};

template<typename Scalar>
Vec2<Scalar> operator+(const Vec2<Scalar>& a, const Vec2<Scalar>& b)
{
    return {a.x + b.x, a.y + b.y};
}

template<typename Scalar>
Vec2<Scalar> operator-(const Vec2<Scalar>& a, const Vec2<Scalar>& b)
{
    return {a.x - b.x, a.y - b.y};
}

template<typename Scalar>
Vec2<Scalar>& operator+=(Vec2<Scalar>& a, const Vec2<Scalar>& b)
{
    return a = a + b;
}

template<typename Scalar>
Vec2<Scalar>& operator-=(Vec2<Scalar>& a, const Vec2<Scalar>& b)
{
    return a = a - b;
}

template<typename Scalar>
Vec2<Scalar> operator*(const Scalar& w, const Vec2<Scalar>& v)
{
    return {v.x * w, v.y * w};
}

template<typename Scalar>
Vec2<Scalar> operator*(const Vec2<Scalar>& v, const Scalar& w)
{
    return w * v;
}

template<typename Scalar>
Scalar norm(const Vec2<Scalar>& a)
{
    return std::sqrt(a.x * a.x + a.y * a.y);
}
@
